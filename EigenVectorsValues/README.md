Ã–zdeÄŸerler, Ã–zvektÃ¶rler ve Makine Ã–ÄŸrenmesindeki RolÃ¼

ğŸ”¹ Kavramsal TanÄ±mlar

Ã–zvektÃ¶r (Eigenvector): Bir matrisle Ã§arpÄ±ldÄ±ÄŸÄ±nda sadece skaler bir katsayÄ± (lambda) kadar yÃ¶nÃ¼ deÄŸiÅŸmeyen vektÃ¶rlerdir.

Ã–zdeÄŸer (Eigenvalue): Bu skaler katsayÄ±nÄ±n kendisidir. Ã–zvektÃ¶re karÅŸÄ±lÄ±k gelen Ã§arpan deÄŸeridir.

 Matematiksel ifade:

Burada  kare matris,  bir Ã¶zvektÃ¶r,  ise karÅŸÄ±lÄ±k gelen Ã¶zdeÄŸerdir.

 Makine Ã–ÄŸrenmesindeki KullanÄ±m AlanlarÄ±

1.  Principal Component Analysis (PCA)

Boyut indirgeme tekniÄŸidir.

Kovaryans matrisinin Ã¶zvektÃ¶rleri, verinin en Ã§ok bilgi taÅŸÄ±yan yÃ¶nleridir.

Ã–zdeÄŸerler, her Ã¶zvektÃ¶rÃ¼n verideki varyansa katkÄ±sÄ±nÄ± belirtir.

 â†’ kovaryans matrisi

2.  Singular Value Decomposition (SVD)

Ã–zellikle gÃ¶rÃ¼ntÃ¼ iÅŸleme ve metin madenciliÄŸi gibi alanlarda kullanÄ±lÄ±r.

Herhangi bir  matrisi:



ÅŸeklinde ayrÄ±ÅŸtÄ±rÄ±labilir. Bu ayrÄ±ÅŸtÄ±rma, verinin Ã¶nemli Ã¶zelliklerini tutan bileÅŸenleri Ã§Ä±karÄ±r.

3.  Google PageRank

Web sayfalarÄ± arasÄ±ndaki baÄŸlantÄ±lar bir olasÄ±lÄ±k matrisi olarak tanÄ±mlanÄ±r.

Bu matrisin dominant Ã¶zvektÃ¶rÃ¼, sayfalarÄ±n "Ã¶nem derecesini" belirler.

4.  Spektral KÃ¼meleme (Spectral Clustering)

Benzerlik matrisi oluÅŸturulur.

Bu matrisin Ã¶zvektÃ¶rleri kullanÄ±larak veri gÃ¶rsel olarak ayrÄ±ÅŸtÄ±rÄ±lÄ±r.

 Teorik Arka Plan

Ã–zdeÄŸer denkleminden karakteristik denklem Ã§Ä±karÄ±lmÄ±ÅŸ:


Determinant ÅŸartÄ±:

 Ã§Ã¶zÃ¼lerek Ã¶zdeÄŸerler hesaplanÄ±r.

Eigen decomposition:



Simetrik matrisler iÃ§in:



SVD ve boyut indirgeme uygulamasÄ± el yazÄ±sÄ±yla Ã§izilmiÅŸ.
